{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EJNUQYYln1-u"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IvG0x_PPo5z3"
   },
   "source": [
    "# Question 1 \n",
    "\n",
    "For this question, you only need to do programming for Part 1.1 - 1.6. You will only be asked to provide answers in Part 1.7. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "ncYW32VZocLf"
   },
   "outputs": [],
   "source": [
    "PATH_TO_Q1_DATA = 'data/HW3_Q1_DATA_10000.csv' #TODO: Change if your path to data is different\n",
    "df_original = pd.read_csv(PATH_TO_Q1_DATA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 19)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Intubated</th>\n",
       "      <th>Pneumonia</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pregnant</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>COPD</th>\n",
       "      <th>Asthma</th>\n",
       "      <th>Immunocompromised</th>\n",
       "      <th>Hypertension</th>\n",
       "      <th>Other_Disease</th>\n",
       "      <th>Cardiovascular_disease</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>Renal_disease</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Exposure_to_others_with_COVID</th>\n",
       "      <th>Has_COVID</th>\n",
       "      <th>ICU</th>\n",
       "      <th>Died</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>54</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>60</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>63</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex Intubated Pneumonia  Age Pregnant Diabetes COPD Asthma  \\\n",
       "0   F         N         N   54        N        N    N      N   \n",
       "1   M         N         Y   30      NaN        N    N      N   \n",
       "2   F         N         N   60        N        Y    N      N   \n",
       "3   M         N         Y   47      NaN        Y    N      N   \n",
       "4   M         N         N   63      NaN        N    N      N   \n",
       "\n",
       "  Immunocompromised Hypertension Other_Disease Cardiovascular_disease Obesity  \\\n",
       "0                 N            N             N                      N       Y   \n",
       "1                 N            N             N                      N       N   \n",
       "2                 N            Y             N                      Y       N   \n",
       "3                 N            N             N                      N       N   \n",
       "4                 N            Y             N                      N       N   \n",
       "\n",
       "  Renal_disease Smoker Exposure_to_others_with_COVID Has_COVID ICU Died  \n",
       "0             N      N                           NaN         Y   N    N  \n",
       "1             N      N                           NaN         Y   N    N  \n",
       "2             N      N                           NaN         Y   N    Y  \n",
       "3             N      N                           NaN         Y   Y    Y  \n",
       "4             N      N                           NaN         Y   N    N  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode data without modifying missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert categorical data to numerical values\n",
    "# drop one of each of the binary categories because it is not necessary (all info is encoded by one column)\n",
    "# add column for missing data\n",
    "# ?? drop missing values instead\n",
    "df=pd.get_dummies(df_original, drop_first=True, dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex_M</th>\n",
       "      <th>Sex_nan</th>\n",
       "      <th>Intubated_Y</th>\n",
       "      <th>Intubated_nan</th>\n",
       "      <th>Pneumonia_Y</th>\n",
       "      <th>Pneumonia_nan</th>\n",
       "      <th>Pregnant_Y</th>\n",
       "      <th>Pregnant_nan</th>\n",
       "      <th>Diabetes_Y</th>\n",
       "      <th>...</th>\n",
       "      <th>Renal_disease_nan</th>\n",
       "      <th>Smoker_Y</th>\n",
       "      <th>Smoker_nan</th>\n",
       "      <th>Exposure_to_others_with_COVID_Y</th>\n",
       "      <th>Exposure_to_others_with_COVID_nan</th>\n",
       "      <th>Has_COVID_nan</th>\n",
       "      <th>ICU_Y</th>\n",
       "      <th>ICU_nan</th>\n",
       "      <th>Died_Y</th>\n",
       "      <th>Died_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Sex_M  Sex_nan  Intubated_Y  Intubated_nan  Pneumonia_Y  \\\n",
       "0   54      0        0            0              0            0   \n",
       "1   30      1        0            0              0            1   \n",
       "2   60      0        0            0              0            0   \n",
       "3   47      1        0            0              0            1   \n",
       "4   63      1        0            0              0            0   \n",
       "\n",
       "   Pneumonia_nan  Pregnant_Y  Pregnant_nan  Diabetes_Y  ...  \\\n",
       "0              0           0             0           0  ...   \n",
       "1              0           0             1           0  ...   \n",
       "2              0           0             0           1  ...   \n",
       "3              0           0             1           1  ...   \n",
       "4              0           0             1           0  ...   \n",
       "\n",
       "   Renal_disease_nan  Smoker_Y  Smoker_nan  Exposure_to_others_with_COVID_Y  \\\n",
       "0                  0         0           0                                0   \n",
       "1                  0         0           0                                0   \n",
       "2                  0         0           0                                0   \n",
       "3                  0         0           0                                0   \n",
       "4                  0         0           0                                0   \n",
       "\n",
       "   Exposure_to_others_with_COVID_nan  Has_COVID_nan  ICU_Y  ICU_nan  Died_Y  \\\n",
       "0                                  1              0      0        0       0   \n",
       "1                                  1              0      0        0       0   \n",
       "2                                  1              0      0        0       1   \n",
       "3                                  1              0      1        0       1   \n",
       "4                                  1              0      0        0       0   \n",
       "\n",
       "   Died_nan  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                  551802\n",
       "Sex_M                                  6267\n",
       "Sex_nan                                   0\n",
       "Intubated_Y                             985\n",
       "Intubated_nan                            11\n",
       "Pneumonia_Y                            6644\n",
       "Pneumonia_nan                             0\n",
       "Pregnant_Y                               72\n",
       "Pregnant_nan                           6280\n",
       "Diabetes_Y                             3104\n",
       "Diabetes_nan                             63\n",
       "COPD_Y                                  376\n",
       "COPD_nan                                 50\n",
       "Asthma_Y                                207\n",
       "Asthma_nan                               49\n",
       "Immunocompromised_Y                     271\n",
       "Immunocompromised_nan                    53\n",
       "Hypertension_Y                         3455\n",
       "Hypertension_nan                         52\n",
       "Other_Disease_Y                         451\n",
       "Other_Disease_nan                        78\n",
       "Cardiovascular_disease_Y                415\n",
       "Cardiovascular_disease_nan               55\n",
       "Obesity_Y                              2305\n",
       "Obesity_nan                              66\n",
       "Renal_disease_Y                         486\n",
       "Renal_disease_nan                        52\n",
       "Smoker_Y                                849\n",
       "Smoker_nan                               55\n",
       "Exposure_to_others_with_COVID_Y        1447\n",
       "Exposure_to_others_with_COVID_nan      5197\n",
       "Has_COVID_nan                             0\n",
       "ICU_Y                                   829\n",
       "ICU_nan                                  11\n",
       "Died_Y                                 3626\n",
       "Died_nan                                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis='rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9999,)\n",
      "(9999, 34)\n"
     ]
    }
   ],
   "source": [
    "# separate into Features X and Target y\n",
    "y = df.loc[:]['Died_Y']\n",
    "print(y.shape)\n",
    "X = df.iloc[:,:-2]  # remove last two columns\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame to store test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe to collect results of all tests\n",
    "df_results = pd.DataFrame(\n",
    "    columns=['Test',\n",
    "             'Description',\n",
    "             'Accuracy',\n",
    "             'Sensitivity',\n",
    "             'Specificity',\n",
    "             'Pos_Predictive_Val',\n",
    "             'Neg_Predictive_Val',\n",
    "             'F1_Score',\n",
    "             'Matthew_Corr_Coef',\n",
    "             'AUC'\n",
    "            ]).astype(\n",
    "    dtype= {'Test':'object',\n",
    "            'Description':'object',\n",
    "            'Accuracy':'float64',\n",
    "            'Sensitivity':'float64',\n",
    "             'Specificity':'float64',\n",
    "             'Pos_Predictive_Val':'float64',\n",
    "             'Neg_Predictive_Val':'float64',\n",
    "             'F1_Score':'float64',\n",
    "             'Matthew_Corr_Coef':'float64',\n",
    "             'AUC':'float64'\n",
    "           })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbJzylg6qXnM"
   },
   "source": [
    "## Part 1.1 Select features and train classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa4bayciquGA"
   },
   "source": [
    "### Part 1.1 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "G_OeUOazqsyA"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Select and apply a filter-based or wrapper-based feature selection method to the data.\n",
    "#   Step 2: Train a classifier using the selected features. Use 10-fold cross validation.\n",
    "\n",
    "# Tip: \n",
    "#   1. You may find the filter-based or wrapper-based methods you used in HW2 useful. \n",
    "\n",
    "#   2. Scikit-learn implement many classifiers, see the comparisons of their \n",
    "#   performance and introductions here:\n",
    "#   https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "#   3. Scikit-learn also implement classifiers with built-in cross validations,\n",
    "#   for example: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define wrapper-based feature selection method and classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "def perform_feature_selection_wrapper(X,y):\n",
    "    svc = SVC(kernel=\"linear\")\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=5,scoring='accuracy',n_jobs=3)\n",
    "    return rfecv.fit(X, y)\n",
    "  \n",
    "def get_feature_list_wrapper(X, support):\n",
    "    features = list()\n",
    "    for i,val in enumerate(support):\n",
    "        if val:\n",
    "            features.append(X.columns[i]) # feature was selected by wrapper method\n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "\n",
    "def build_X_from_features(X, list_features):\n",
    "    return X.loc[:][list_features]\n",
    "\n",
    "def train_classifier(X,y,k):\n",
    "    clf = RidgeClassifierCV(alphas=[1e-3, 1e-2, 1e-1, 1],cv=k)\n",
    "    return clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform feature selection and classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 48s, sys: 1.27 s, total: 1min 49s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# runtime - 3.4 s (1000 records, 10 fold, 3 cores)\n",
    "# runtime - 6 min (10000 records, 10 fold, 3 cores)\n",
    "\n",
    "# feature selection\n",
    "rfecv = perform_feature_selection_wrapper(X,y)\n",
    "features_wrapper = get_feature_list_wrapper(X,rfecv.support_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 s, sys: 39.8 ms, total: 1.15 s\n",
      "Wall time: 304 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# classification\n",
    "X_wrapper = build_X_from_features(X,features_wrapper)\n",
    "\n",
    "clf = train_classifier(X_wrapper,y,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate metrics\n",
    "- Accuracy\n",
    "- Sensitivity & Specificity\n",
    "- The positive and negative predictive values \n",
    "- F1-score\n",
    "- The Matthews Correlation Coefficient\n",
    "- AUC (Area under the ROC curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def get_confusion_matrix(y_true,y_predict):\n",
    "    '''\n",
    "    Calculates the confusion matrix for a given X,y and classifier.\n",
    "    '''\n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_predict)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print('TN:',tn)\n",
    "    print('FP:',fp)\n",
    "    print('FN:',fn)\n",
    "    print('TP:',tp)\n",
    "    print('TOTAL:',tp + tn + fp + fn)\n",
    "    \n",
    "    return cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calc_classifier_metrics(cm, y_true, y_predict):\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # accuracy\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    \n",
    "    # sensitivity\n",
    "    sen = tp / (tp + fn)\n",
    "    \n",
    "    # specificity\n",
    "    spec = tn / (tn + fp)\n",
    "    \n",
    "    # precision\n",
    "    prec = tn / (tn + fp)\n",
    "    \n",
    "    # positive predictive value\n",
    "    ppv = tp / (fp + tp) # ?? check correctness\n",
    "    \n",
    "    # negative predictive value\n",
    "    npv = tn / (fn + tn)\n",
    "    \n",
    "    # f1 score\n",
    "    f1 = 2 * (prec * sen) / (prec + sen) \n",
    "    \n",
    "    # matthew correlation coefficient\n",
    "    mcc = matthews_corrcoef(y_true,y_predict)\n",
    "    \n",
    "    # area Under the receiver (AUC)\n",
    "    auc = roc_auc_score(y_true, y_predict)\n",
    "    \n",
    "    # return numpy array  \n",
    "    metrics = [acc,sen,spec,ppv,npv,f1,mcc,auc]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TN: 5556\n",
      "FP: 817\n",
      "FN: 2013\n",
      "TP: 1613\n",
      "TOTAL: 9999\n"
     ]
    }
   ],
   "source": [
    "y_predict = clf.predict(X_wrapper)\n",
    "cm = get_confusion_matrix(y,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.716971697169717,\n",
       " 0.4448428019856591,\n",
       " 0.8718029185626863,\n",
       " 0.6637860082304526,\n",
       " 0.734046769718589,\n",
       " 0.589095831961823,\n",
       " 0.3549254099545765,\n",
       " 0.6583228602741727]"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_results = calc_classifier_metrics(cm,y,y_predict)\n",
    "wrapper_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add metrics to results DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_row(df, test, description, metrics):\n",
    "    \n",
    "    data = [test,description] + metrics\n",
    "    print(data)  \n",
    "    new_row = pd.Series(data, index = df.columns)\n",
    "    print(new_row)\n",
    "    return df.append(new_row,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'B', 0.716971697169717, 0.4448428019856591, 0.8718029185626863, 0.6637860082304526, 0.734046769718589, 0.589095831961823, 0.3549254099545765, 0.6583228602741727]\n",
      "Test                         A\n",
      "Description                  B\n",
      "Accuracy              0.716972\n",
      "Sensitivity           0.444843\n",
      "Specificity           0.871803\n",
      "Pos_Predictive_Val    0.663786\n",
      "Neg_Predictive_Val    0.734047\n",
      "F1_Score              0.589096\n",
      "Matthew_Corr_Coef     0.354925\n",
      "AUC                   0.658323\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_results_2 = add_row(df_results,'A','B',wrapper_results )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test</th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Pos_Predictive_Val</th>\n",
       "      <th>Neg_Predictive_Val</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Matthew_Corr_Coef</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>0.716972</td>\n",
       "      <td>0.444843</td>\n",
       "      <td>0.871803</td>\n",
       "      <td>0.663786</td>\n",
       "      <td>0.734047</td>\n",
       "      <td>0.589096</td>\n",
       "      <td>0.354925</td>\n",
       "      <td>0.658323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Test Description  Accuracy  Sensitivity  Specificity  Pos_Predictive_Val  \\\n",
       "0    A           B  0.716972     0.444843     0.871803            0.663786   \n",
       "\n",
       "   Neg_Predictive_Val  F1_Score  Matthew_Corr_Coef       AUC  \n",
       "0            0.734047  0.589096           0.354925  0.658323  "
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 10 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Test                1 non-null      object \n",
      " 1   Description         1 non-null      object \n",
      " 2   Accuracy            1 non-null      float64\n",
      " 3   Sensitivity         1 non-null      float64\n",
      " 4   Specificity         1 non-null      float64\n",
      " 5   Pos_Predictive_Val  1 non-null      float64\n",
      " 6   Neg_Predictive_Val  1 non-null      float64\n",
      " 7   F1_Score            1 non-null      float64\n",
      " 8   Matthew_Corr_Coef   1 non-null      float64\n",
      " 9   AUC                 1 non-null      float64\n",
      "dtypes: float64(8), object(2)\n",
      "memory usage: 208.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "df_results_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGcEfPHSy2YP"
   },
   "source": [
    "### Part 1.2 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i1LoJQbly2YQ"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Select a learning algorithm that performs embedded feature selection. \n",
    "#   Step 2: Train a classifier using the selected features. Use 10-fold cross validation.\n",
    "\n",
    "# Tip: \n",
    "#   1. Scikit-learn implement many classifiers, see the comparisons of their \n",
    "#   performance and introductions here:\n",
    "#   https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html\n",
    "\n",
    "#   2. Scikit-learn also implement classifiers with built-in cross validations,\n",
    "#   for example: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifierCV.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform feature selection using embedded method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def train_embedded_model(X,y):\n",
    "    sel = SelectFromModel(RandomForestClassifier())\n",
    "    return sel.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_embedded,y_train_embedded,X_test_embedded,y_test_embedded = train_test_split(data,test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier using selected features from embedded method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RdEACG6sy2YU"
   },
   "source": [
    "### Part 1.3 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6KIVVaZy2YU"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Select and apply a data imputation method to handle the missing data.\n",
    "#   Step 2: Apply the  wrapper based feature selection method you used in part 1.1.\n",
    "#   Step 3: Train a classifier using the selected features. Use the same classifier you used in part 1.1. Use 10-fold cross validation.\n",
    "\n",
    "# Tip: \n",
    "#   1. Sciki-learn implements different imputation methods. Take a look at https://scikit-learn.org/stable/modules/impute.html\n",
    "#   and use the one you think most appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKXCaHm_y2YZ"
   },
   "source": [
    "### Part 1.4 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdlwFY4ty2YZ"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Apply a data imputation method to eliminate any missing values in the data. Use the same method you used in part 1.3. \n",
    "#   Step 2: Train a classifier. Use the same classifier you used in part 1.2. Use 10-fold cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pmT3MFZcy2Yj"
   },
   "source": [
    "### Part 1.5 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4gzJms7Fy2Yj"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Apply a data imputation method to eliminate any missing values in the data. Use the same method you used in parts 1.3 & 1.4. \n",
    "#   Step 2: Select a learning algorithm that performs cost-sensitive learning. \n",
    "#   Step 3: Adjust the costs until you find a classifier that maximizes the F1-score, subject to the constraint that it achieves 95% sensitivity for the label ‘Y’.  Use 10-fold cross validation.\n",
    "\n",
    "# Tip: \n",
    "#   1. F1-score: https://en.wikipedia.org/wiki/F1_score\n",
    "#   2. Scikit-learn supports extending the classifiers to cost-sensitive learning.\n",
    "#   Take a look at this tutorial: https://machinelearningmastery.com/cost-sensitive-learning-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVYJjxGby2Yn"
   },
   "source": [
    "### Part 1.6 Work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kcf_UQDgy2Yo"
   },
   "outputs": [],
   "source": [
    "# TODO: \n",
    "#   Step 1: Implement a function calculating the weighted average F1-score, following \n",
    "#       the steps in the homework problem statement.\n",
    "#   Step 2: Find a classifier that achieves a weighted average F1-score of at least 0.74 using 10-fold cross validation.\n",
    "\n",
    "# Tip: \n",
    "#   1. F1-score: https://en.wikipedia.org/wiki/F1_score\n",
    "#   2. Scikit-learn supports extending the classifiers to cost-sensitive learning.\n",
    "#   Take a look at this tutorial: https://machinelearningmastery.com/cost-sensitive-learning-for-imbalanced-classification/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ii4wINe7y2Yr"
   },
   "source": [
    "### Part 1.7 Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OkoYhmvSy2Ys"
   },
   "outputs": [],
   "source": [
    "# Tip:\n",
    "#   1. Scikit-learn implements different evaluation metrics for classifications,\n",
    "#   see: https://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMVemn4By2Yw"
   },
   "source": [
    "### Part 1.7 Answers\n",
    "\n",
    "1. Create a ROC plot with the results from parts 1.1 to 1.6. \n",
    "2. Create a table with the following performance metrics for the results from parts 1.1 to 1.6:\n",
    "    * Accuracy\n",
    "    * Sensitivity & Specificity\n",
    "    * The positive and negative predictive values\n",
    "    * F1-score\n",
    "    * The Matthews Correlation Coefficient\n",
    "    * AUC (Area under the ROC curve)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "02_518_02_718_HW_3_Template.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
